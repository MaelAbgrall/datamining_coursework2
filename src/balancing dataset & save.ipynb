{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# libs\n",
    "import sklearn.cluster as skcluster\n",
    "import numpy\n",
    "import pandas\n",
    "\n",
    "# project files\n",
    "import utils.filehandler as filehandler\n",
    "import view.plot as viewer\n",
    "import utils.learning as lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing ../fer2018/fer2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Code_ecole\\datamining\\datamining_coursework2\\src\\utils\\filehandler.py:21: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  data = data_frame.as_matrix()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "importation done in: 12.172155141830444\n",
      "happy:..... 8989\n",
      "sad:....... 6077\n",
      "angry:..... 4953\n",
      "disgust:... 547\n",
      "fear:...... 5121\n",
      "neutral:... 6198\n",
      "surprise:.. 4002\n",
      "train balanced: 3829\n",
      "validation set: 32065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"dataset3 = filehandler.import_csv('../fer2018/fer2018.csv')\\n#(x_train, y_train, x_validation, y_validation) = filehandler.classic_split(dataset, 0.75)\\n(x_train3, y_train3, x_validation3, y_validation3) = filehandler.balance_dataset(dataset, 1.)\\n\\n\\ndataset4 = filehandler.import_csv('../fer2018/fer2018.csv')\\n#(x_train, y_train, x_validation, y_validation) = filehandler.classic_split(dataset, 0.75)\\n(x_train4, y_train4, x_validation4, y_validation4) = filehandler.balance_dataset(dataset, 1.)\\n\\n\\ndataset5 = filehandler.import_csv('../fer2018/fer2018.csv')\\n#(x_train, y_train, x_validation, y_validation) = filehandler.classic_split(dataset, 0.75)\\n(x_train5, y_train5, x_validation5, y_validation5) = filehandler.balance_dataset(dataset, 1.)\\n# dictionary to save and compare accuracy for different amounts of attributes\\nacc_dct = {}\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining hyperparameters\n",
    "Kcluster = 7 # there is 7 emotions\n",
    "\n",
    "# import data\n",
    "dataset = filehandler.import_csv('../fer2018/fer2018.csv')\n",
    "#(x_train, y_train, x_validation, y_validation) = filehandler.classic_split(dataset, 0.75)\n",
    "(x_train1, y_train1, x_validation1, y_validation1) = filehandler.balance_dataset(dataset, 1.)\n",
    "\n",
    "\n",
    "\"\"\"dataset2 = filehandler.import_csv('../fer2018/fer2018.csv')\n",
    "#(x_train, y_train, x_validation, y_validation) = filehandler.classic_split(dataset, 0.75)\n",
    "(x_train2, y_train2, x_validation2, y_validation2) = filehandler.balance_dataset(dataset, 1.)\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"dataset3 = filehandler.import_csv('../fer2018/fer2018.csv')\n",
    "#(x_train, y_train, x_validation, y_validation) = filehandler.classic_split(dataset, 0.75)\n",
    "(x_train3, y_train3, x_validation3, y_validation3) = filehandler.balance_dataset(dataset, 1.)\n",
    "\n",
    "\n",
    "dataset4 = filehandler.import_csv('../fer2018/fer2018.csv')\n",
    "#(x_train, y_train, x_validation, y_validation) = filehandler.classic_split(dataset, 0.75)\n",
    "(x_train4, y_train4, x_validation4, y_validation4) = filehandler.balance_dataset(dataset, 1.)\n",
    "\n",
    "\n",
    "dataset5 = filehandler.import_csv('../fer2018/fer2018.csv')\n",
    "#(x_train, y_train, x_validation, y_validation) = filehandler.classic_split(dataset, 0.75)\n",
    "(x_train5, y_train5, x_validation5, y_validation5) = filehandler.balance_dataset(dataset, 1.)\n",
    "# dictionary to save and compare accuracy for different amounts of attributes\n",
    "acc_dct = {}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas.DataFrame((y_train1, x_train1), columns=[\"y_train\", \"x_train\"])\n",
    "#numpy.array((y_train1, x_train1))\n",
    "\n",
    "train = []\n",
    "val = []\n",
    "\n",
    "for position in range(x_train1.shape[0]):\n",
    "    train.append((y_train1[position], x_train1[position]))\n",
    "#train = numpy.array(train)\n",
    "\n",
    "for pos in range(x_validation1.shape[0]):\n",
    "    val.append((y_validation1[pos], x_validation1[pos]))\n",
    "#val = numpy.array(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_frame = pandas.DataFrame(train, columns=[\"y_train\", \"x_train\"])\n",
    "validation_frame = pandas.DataFrame(val, columns=[\"y_train\", \"x_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frame.to_csv(\"train_balanced.csv\", index=False)\n",
    "validation_frame.to_csv(\"validation_balanced.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
